---
layout: page
title: "考点"
date: 2020-05-23
author: ynwa
category: review
tags: stars
finished: false
---

# MapReduce的考点

### 简述执行过程

1. 5个步骤，input->map->shuffle->reduce->output

2. Shuffle ，分为Map端（partition、sort、spill、merge，在sort和spill之间可选combine，merge之前可选combine）、Reduce端（copy、merge，merge之前可选combine）

3. combine的场景是，将多个有序数组合并到一个数组，算法两层，外循环为主数组，内循环的逻辑是从一个有序数组中进行查询，二分查找是最优算法，算法复杂度为logn

   所以，MapReduce的sort看起来是比较有用的，但是也比较损耗性能

4. spark的udaf实现

   initialize -> update -> merge -> evaluate

5. hive的udaf实现
+ map+reduce = PARTIAL1(mapper) ， FINAL(reducer)
+ map+reduce+combine = PARTIAL1(mapper)，PARTIAL2(combiner)，FINAL(reducer)
+ map = COMPLETE（mapper）

6. partition，默认是HashPartition，也可自定义，所以部分数据倾斜问题是出在key的hash碰撞

7. Map个数，与文件数、hdfs的block默认大小、mapred.map.tasks参数相关

8. Reduce个数，hive.exec.reducers.bytes.per.reducer 相关



# Hive的考点

### 数据倾斜

资源分配不均的问题，体现在MapReduce阶段的Map个数、shuffle的原理、reduce的个数

### hive.groupby.skewindata

https://www.cnblogs.com/wanfeng1937/p/10755178.html

这是个南非荷兰语

针对count distinct的场景提供优化，负载均衡

### hive.map.aggr

map端聚合

### SQL执行过程

Parser -> LogicPlan -> Optimizer ->PhsicalPlan

语法词法解析器 -> 逻辑执行计划 -> 优化器 -> 物理执行计划

SQL -> AST(abstract syntax tree) -> Task(MapRedTask,FetchTask) -> QueryPlan(Task集合) -> Job(Yarn)



理解Explain的结果：stage的序列、stage的依赖、stage的具体描述

### SQL操作类型对应的MR流程

Join

count+groupby

### 文件格式和压缩




# Flink的考点

### 与spark streaming的对比



### 基于savepoint的任务代码升级

