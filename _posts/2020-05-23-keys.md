---
layout: page
title: "考点"
date: 2020-05-23
author: ynwa
category: review
tags: stars
finished: false
---

# MapReduce的考点

### 简述执行过程

1. 5个步骤，input->map->shuffle->reduce->output

2. Shuffle ，分为Map端（partition、sort、spill、merge，在sort和spill之间可选combine，merge之前可选combine）、Reduce端（copy、merge，merge之前可选combine）

3. combine的场景是，将多个有序数组合并到一个数组，算法两层，外循环为主数组，内循环的逻辑是从一个有序数组中进行查询，二分查找是最优算法，算法复杂度为logn

4. hive和spark的udaf实现差异

+ spark: initialize -> update -> merge -> evaluate
+ 

5. 所以，MapReduce的sort看起来是比较有用的，但是也比较损耗性能

6. partition，默认是HashPartition，也可自定义，所以部分数据倾斜问题是出在key的hash碰撞

7. Map个数，与文件数、hdfs的block默认大小、mapred.map.tasks参数相关

8. Reduce个数，hive.exec.reducers.bytes.per.reducer 相关



# Hive的考点

### 数据倾斜

资源分配不均的问题，体现在MapReduce阶段的Map个数、shuffle的原理、reduce的个数

### SQL执行过程

